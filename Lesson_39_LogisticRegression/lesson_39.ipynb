{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия\n",
    "\n",
    "Классификация - это задача предсказания категориального результата. Целевая переменная принимает ограниченный набор классов.\n",
    "\n",
    "Метрики классификации: Accuracy, F1-score, Recall, Precision.\n",
    "\n",
    "Логистическая регрессия - это метод прогнозирования бинарных исходов с помощью сигмоидной функции.\n",
    "Логистическая функция преобразует линейные данные в значение вероятности событий. Модель: S-образная сигмоида.\n",
    "Логистическая регрессия - линейная.\n",
    "\n",
    "Преимущества:\n",
    "* интерпретируемость\n",
    "* простота\n",
    "* многофакторность\n",
    "\n",
    "Формула логистической регрессии\n",
    "\n",
    "$\n",
    "P(y=1 | x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x1 + ... + \\beta_n x_n)}}\n",
    "$\n",
    "\n",
    "Сигмоида отображает линейную комбинацию факторов в вероятность от 0 до 1.\n",
    "\n",
    "Вероятность, близкая к нулю - отнесение результата к нулевому классу.\n",
    "\n",
    "Вероятность, близкая к единице - отнесение результата к единичному классу.\n",
    "\n",
    "Геометрическая интерпретация: гиперплоскость; разделяет пространство признаков на два класса.\n",
    "\n",
    "Интерпретация коэффициентов: \n",
    "\n",
    "Обучение модели: градиентный спуск, минимизируя функцию потерь. Регуляризация устраняет переобучение.\n",
    "\n",
    "Функция потерь (Log-Loss): наказывает за уверенные, но неправильные прогнозы. Основана на кросс-энтропии из теории информации.\n",
    "\n",
    "Функция потерь (Focal Loss): меньше штрафует за более уверенные ответы.\n",
    "\n",
    "Проблема: переобучение (overfitting)\n",
    "\n",
    "Борются с помощью регуляризации:\n",
    "  * L1 регуляризация: коэффициент, умноженный на квадрат признака\n",
    "  * L2 регуляризация: коэффициент, умноженный на модуль признака\n",
    "\n",
    "Не даёт слишком сильно влиять на веса.\n",
    "\n",
    "Ограничения:\n",
    "* мультиколлинеарность: сильно коррелированные признаки затрудняют работу модели\n",
    "* пропущенные значения: отсутствие данных снижает точность и надёжность предсказаний\n",
    "* неэффективность в сложных задачах: плохо работает на нелинейных и сложных для разделения данных\n",
    "* сравнение с другими моделями: деревья, SVM и нейросети часто превосходят по точности\n",
    "\n",
    "Метрики AUC и замена Accuracy\n",
    "* AUC (Area Under Curve): оценивает способность модели разделять классы.\n",
    "* ROC-AUC и PR-AUC: лучше подходят для оценки моделей при дисбалансе.\n",
    "* Высокая accuracy обманчива при редком классе.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
